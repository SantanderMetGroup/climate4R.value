{
    "collab_server" : "",
    "contents" : "#\n# Case Study:\n# caseStudy={'Lake Arreskov','Denmark',55.16,10.31,'sub-daily','both';...\n#   'Wupper Reservoir','Germany',51.1983,7.3011,'hourly or daily','both';...\n#   'Burrishoole Catchment','Ireland',[53.8833 54.05],[-9.6833 -9.4833],'Daily','both';...\n#   'Vansjo Catchment','Norway',[59.31 59.90],[10.63 11.25],'Daily','both';...\n#   'Sau Reservoir','Spain',41.9702,2.3994,'Daily or sub-daily','both';...\n#   'Mt. Bold Reservoir','Australia',[-35.15 -35.0167],[138.6667 138.8167],'6-hourly','both'};\n####################################################################################################\n## Example of Data Reference Sintax: How to build the directory structure and file naming         ##\n## considering observations, reanalysis, seasonal forecast or climate change projections          ##\n## SEE the proposal for the WATExR Archive Design in:                                             ## \n## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit           ##\n####################################################################################################\n#   Lake (lake_id): Is an identifier for the lake/case study.\n#   institution (institute_id): Is an identifier for the institution that is responsible for the scientific aspects of the simulation.\n#   LakeModelName (driving_lake_model_id): is an identifier of the driving lake model.\n#     The name consists of an institute identifier and a lake model identifier. \n#     The two parts of the name are separated by a '-' (dash). Note that dashes in either of the two parts are allowed. \n#   ClimateModelName (driving_climate_model_id) is an identifier of the driving climate model.\n#     The name consists of an institute identifier and a climate model identifier. \n#     The two parts of the name are separated by a '-' (dash). Note that dashes in either of the two parts are allowed.\n#     For observations or reanalysis indicate the name of the data set as model identifier. \n#   ExperimentName (driving_experiment_name) is:\n# Climate change projection: either \"evaluation\" or the value of the CMIP5 experiment_id of the data used (\"historical\", \"rcp4.5\", \"rcp8.5\", etc)\n# Seasonal Forecasts: \"seasonal\"\n# Observed data: \"observations\"\n# Reanalysis: \"reanalysis\"\n#   EnsembleMember (driving_model_ensemble_member) identifies the ensemble member of the global climate model, seasonal or climate change, experiment that produced the forcing data.\n# Climate change: the format should be the same used in the CMIP5 (e.g. r1i1p1)\n# Seasonal Forecasts: this element is defined by the member (e.g. member01 for the first member).\n# Reanalysis: Set this element as member01 for reanalysis data.\n#   Frequency (frequency) is the output frequency indicator: 6hr=6 hourly, day=daily, etc.\n#   StartTime and EndTime indicate the time span of the file content. The format is YYYY[MM[DD[HH[MM]]]], i.e. the year is represented by 4 digits, \n# while the month, day, hour, and minutes are represented by exactly 2 digits, if they are present at all. In accordance with CMIP5, only those \n# digits have to be included that are necessary to indicate the file content. The two dates are separated by a dash. All time stamps refer to UTC.2.2 \n##################################################################################################################################################################\n\n# Install required packages. RUN JUST THE FIRST TIME.\ndevtools::install_github(c(\"SantanderMetGroup/loadeR.java\", \"SantanderMetGroup/loadeR@devel\",\n                           \"SantanderMetGroup/transformeR\", \"SantanderMetGroup/loadeR.ECOMS\",  \n                           \"SantanderMetGroup/visualizeR\", \"SantanderMetGroup/convertR\",\n                           \"SantanderMetGroup/drought4R@devel\", \"SantanderMetGroup/downscaleR@devel\")) \n\n# Load packages.\noptions(java.parameters = \"-Xmx8000m\")\nlibrary(transformeR)\nlibrary(loadeR.ECOMS)\nlibrary(loadeR)\nlibrary(visualizeR)\nlibrary(convertR)\nlibrary(drought4R)\nlibrary(downscaleR)\n\n####### GENERAL SETTINGS THAT NEED TO BE DEFINED: --------------------------------------------------\n\n# Output path where the data will be saved (change to your local path)\ndir.data <- '/oceano/gmeteo/WORK/PROYECTOS/2017_WATExR/data/'\ndir.Rdata <- '/oceano/gmeteo/WORK/PROYECTOS/2017_WATExR/Rdata/'\n\n# Define the geographical domain to be loaded\nlonLim <- c(32, 33) \nlatLim <- c(43, 44)\n# Alternatively...\n# Define the geographical location, a single point, in this case the interpolation using interpGrid function is not required (but will work even if applying interpGrid)\n# e.g. Black sea:\n# lonLim <- 32.625 \n# latLim <- 43.177\n\n# Define the coordinates and name of the lake\nlake <- list(x = 32.625, y = 43.177) # black sea\nlakename <- \"BlackSea\"\n\n# Define the dataset \ndataset <- \"System4_seasonal_15\" # or \"CFSv2_seasonal\"\n\n# Login in the TAP-UDG the climate4R libraries \n# More details about UDG in https://doi.org/10.1016/j.cliser.2017.07.001\nloginUDG(\"WATExR\", \"1234567890\")\n\n# Check available variables in the dataset (System4)  \ndi <- dataInventory(\"http://www.meteo.unican.es/tds5/dodsC/system4/System4_Seasonal_15Members.ncml\") # or \"http://meteo.unican.es/tds5/dodsC/cfsrr/CFSv2_Seasonal.ncml\"\nnames(di)\n\n# Path to the observational data (change to your local path).\ndir.Rdata.obs <- \"/oceano/gmeteo/WORK/PROYECTOS/2017_WATExR/Rdata/PIK_Obs-EWEMBI_1_2_3_4_5_6_7_8_9_10_11_12_uas_vas_ps_tas_pr_rsds_rlds_hurs_cc_petH.rda\"\nobs.data <- get(load(dir.Rdata.obs))\n\n# Define the variables to be loaded (the same as in the observational data, \n# except clould cover (cc) and evapotranspiration (petH))\nsapply(obs.data, function(x) getVarNames(x)) # to check the variables in the observational data.\nvariables <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\", \"hurs\")\n\n# Define daily aggregation function for each variable selected\naggr.fun <- c(\"mean\", \"mean\", \"mean\", \"mean\", \"sum\", \"mean\", \"mean\", \"mean\")\n\n# Define the members\nmem <- 1:15\n# Define the lead month\nlead.month <- 0\n# Define period and season\nyears <- 1981:2000\nseason <- c(11,12,1,2) # Winter\n\n########## DATA LOADING AND TRANSFORMATION ----------------------------------------------------------\n\n# Load seasonal forecast data (System4 or CFS) with function loadECOMS\n# Data is loaded in a loop (funciÃ³n lapply) to load all variables in a single code line.\n# A list of grids is obtained, each slot in the list corresponds to a variable\ndata.prelim <- lapply(1:length(variables), function(x) loadECOMS(dataset, var = variables[x], years = years, \n                                                          members = mem, leadMonth = lead.month,\n                                                          lonLim = lonLim, latLim = latLim, season = season, \n                                                          time = \"DD\", aggr.d = aggr.fun[x]))\nnames(data.prelim) <- variables\n\n# Bilinear interpolation of the data to the location of the lake\ndata.interp <- lapply(data.prelim, function(x) interpGrid(x, new.coordinates = lake, \n                                                          method = \"bilinear\", \n                                                          bilin.method = \"akima\"))\n\n# Convert pressure units to millibars with function udConvertGrid from package convertR.\ndata.interp$ps <- udConvertGrid(data.interp$ps, new.units = \"millibars\")\n\n# Compute cloud cover with function rad2cc\nclt <- rad2cc(rsds = data.interp$rsds, rlds = data.interp$rlds)\nclt$Variable$varName <- \"cc\"\n\n# Put all variables together\ndata <- c(data.interp, \"cc\" = list(clt))\n\n############################################################################################\n############### RUN THE FOLLOWING CODE CHUNK IF YOU NEED POTENTIAL EVAPOTRANSPIRATION ######\n# Load needed variables \ntasmin <- loadECOMS(dataset, var = \"tasmin\", years = years, \n                    lonLim = lonLim, latLim = latLim, \n                    leadMonth = lead.month, members = mem,\n                    season = season, time = \"DD\", aggr.d = \"min\")\ntasmax <- loadECOMS(dataset, var = \"tasmax\", years = years, \n                    lonLim = lonLim, latLim = latLim, \n                    leadMonth = lead.month, members = mem,\n                    season = season, time = \"DD\", aggr.d = \"max\")\n\n# Compute potential evapotranspiration with function petGrid from package drought4R\n# For daily data the implemented method is hargreaves-samani (See ?petGrid for details):\npetH <- petGrid(tasmin = tasmin, \n                tasmax = tasmax,\n                method = \"hargreaves-samani\")\n\n# bilinear interpolation \npetH.interp <- interpGrid(petH, new.coordinates = lake, method = \"bilinear\", bilin.method = \"akima\")\npetH.interp$Variable$varName <- \"petH\"\n\n# Put all variables together\ndata <- c(data.interp, \"cc\" = list(clt), \"petH\" = list(petH.interp))\n###################### END OF THE CHUNK ####################################################\n############################################################################################\n\n##### BIAS CORRECTION -----------------------------------------------------------------------\n# Subset all datasets to the same Dates as the hindcast precipitation. Note that we compute daily accumulated \n# precipitation, for this reason this variable has no value for the first day of every season.  \nif (sum(names(data)==\"pr\")>0){\n  data <- lapply(1:length(data), function(x)  {intersectGrid(data[[x]], data[[which(names(data)==\"pr\")]], type = \"temporal\", which.return = 1)}) \n  names(data) <- sapply(data, function(x) getVarNames(x))\n  obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)}) \n  names(obs.data) <- sapply(obs.data, function(x) getVarNames(x))\n} else{\n  obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)}) \n  names(obs.data) <- sapply(obs.data, function(x) getVarNames(x))  \n}\n\n# Check variable consistency\nif (!identical(names(obs.data), names(data))) stop(\"variables in obs.data and data (seasonal forecast) do not match.\")\n\n# Bias correction with leave-one-year-out (\"loo\") cross-validation\n# type ?biasCorrection in R for more info about the parameter settings for bias correction.\ndata.bc.cross <- lapply(1:length(data), function(x)  {\n    precip <- FALSE\n    if (names(data)[x] == \"pr\") precip <- TRUE\n    biasCorrection(y = obs.data[[x]], x = data[[x]], \n                method = \"eqm\", cross.val = \"loo\",\n                precipitation = precip,\n                wet.threshold = 1,\n                join.members = TRUE)\n  }) \nnames(data.bc.cross) <- names(data)\n# Bias correction without cross-validation\ndata.bc <- lapply(1:length(data), function(v)  {\n    pre <- FALSE\n    if (names(data)[v] == \"pr\") pre <- TRUE\n    biasCorrection(y = obs.data[[v]], x = data[[v]], \n                 method = \"eqm\",\n                 precipitation = pre,\n                 wet.threshold = 1,\n                 join.members = TRUE)\n}) \nnames(data.bc) <- names(data)  \n\n# save Rdata (*.rda file)\nsave(data, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_raw.rda\"))\nsave(data.bc.cross, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BCcross.rda\"))\nsave(data.bc, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BC.rda\"))\n\n########## BUILD FINAL DATA AND EXPORT ACCORDING TO THE WATExR ARCHIVE DESIGN -----------------------\n## SEE the proposal for the WATExR Archive Design in:                                            \n## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit\n\n# Select the object to export (can be 'data.bc', 'data.bc.cross' or 'data')\ndatatoexport <- data.bc\n\n# Collect some common metadata (e.g. from variable uas)\ndates <- datatoexport[[1]]$Dates\nxycoords <- getCoordinates(datatoexport[[1]])\n\n# Give format to dates\nyymmdd <- as.Date(dates$start)\nhhmmss <- format(as.POSIXlt(dates$start), format = \"%H:%M:%S\") \n\n# Define metadata to generate the file name\ninstitution <- \"UC\"\nlake_id <- lakename\nClimateModelName <- dataset\nExperimentName <- \"seasonal\"\nfreq <- \"day\"\n\n# Save a single file for each member\nfor (i in mem) {\n  # Build data.frame for a single member\n  single.member <- lapply(datatoexport, function(x) subsetGrid(x, members = i))\n  single.member <- lapply(single.member, function(x) x$Data)\n  # Remove unwanted variables\n  single.member[\"rsds\"] <- NULL\n  single.member[\"rlds\"] <- NULL\n  # data.frame creation\n  df <- data.frame(c(list(\"dates1\" = yymmdd, \"dates2\" = hhmmss)), single.member)\n  if (i < 10) {\n    member <- paste0(\"member0\", i, sep = \"\", collapse = NULL)\n  } else {\n    member <- paste0(\"member\", i, sep = \"\", collapse = NULL)\n  }    \n  startTime <- format(as.POSIXlt(yymmdd[1]), format = \"%Y%m%d\")\n  endTime <- format(tail(as.POSIXlt(yymmdd), n = 1), format = \"%Y%m%d\")\n  dirName <- paste0(dir.data, lake_id, \"/CLIMATE/\", lake_id, \"_\", institution, \"_\", ClimateModelName, \"_\", ExperimentName, \"_\", member, \"_\", freq,\"_\", startTime, \"-\", endTime, \"/\", sep = \"\", collapse = NULL)\n  dir.create(dirName, showWarnings = TRUE, recursive = TRUE, mode = \"0777\")\n  write.table(df, paste0(dirName, \"meteo_file.dat\", sep = \"\", collapse = NULL), sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE)\n}\n\n\n\n\n",
    "created" : 1551719844008.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1625886977",
    "id" : "AA5AE23B",
    "lastKnownWriteTime" : 1550830079,
    "last_content_update" : 1550830079,
    "path" : "/oceano/gmeteo/WORK/PROYECTOS/2017_WATExR/scripts/WP2/seasonalForecast.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}